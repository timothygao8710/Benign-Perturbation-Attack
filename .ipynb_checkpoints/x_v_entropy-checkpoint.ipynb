{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95624224-e802-4a83-84ef-1d10fa620a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/linux/mambaforge-3.11/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222d6f1c-690f-41b9-a463-635ccb7c67b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (4.42.4)\n",
      "Requirement already satisfied: torch in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.26.1)\n",
      "Requirement already satisfied: lit in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from triton==2.0.0->torch) (16.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/linux/mambaforge-3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/linux/mambaforge-3.11/bin/python -m pip install transformers torch pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364cee5-0a9c-49e8-8456-0c6313b01486",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# is semantic entropy correlated with accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921ad8a-9693-441f-9654-548ea1c4ed3a",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# is semantic entropy correlated with accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5912cb4-0b2c-49f4-b8c8-192766eb1b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/timothygao/.local/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(prompts, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     15\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:3199\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3195\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3196\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3197\u001b[0m         )\n\u001b[1;32m   3198\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 3199\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3200\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3201\u001b[0m         )\n\u001b[1;32m   3203\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[1;32m   3204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Get token IDs for A, B, C, D\n",
    "    allowed_tokens = tokenizer.convert_tokens_to_ids([\"A\", \"B\", \"C\", \"D\"])\n",
    "    \n",
    "    # Create a logits bias tensor\n",
    "    logits_bias = torch.full((1, tokenizer.vocab_size), -float('inf')).to(model.device)\n",
    "    logits_bias[0, allowed_tokens] = 0  # Allow only A, B, C, D\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            logits_processor=[LogitsProcessorList([CustomLogitsProcessor(logits_bias)])]\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Custom LogitsProcessor to apply the logits bias\n",
    "class CustomLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, logits_bias):\n",
    "        self.logits_bias = logits_bias\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        return scores + self.logits_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184cbcb9-a66e-4a88-b149-0a3bb75a2c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84758a9f-45e8-4fa4-acd1-0662dc72a38b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# is semantic entropy correlated with sensitivity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128d638-0b92-4c78-8ca3-5371b44a8f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
